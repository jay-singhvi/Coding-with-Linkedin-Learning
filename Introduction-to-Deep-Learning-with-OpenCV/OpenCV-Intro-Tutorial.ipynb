{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download file to download YOLO_v3 | Download Download Ex_Files_Deep_Learning_OpenCV.zip with file size 1.32GB (linkedin.com)\n",
    "\n",
    "https://www.linkedin.com/ambry/?x-li-ambry-ep=AQIxmk7rues23QAAAY9-Tg9B1SzW1TU0WZDkuSjzTNnK-3HGWJkAkw-SAnAheiYLm1bNbw-Gi29uRh1COSKPuRLBbs4CR9nW6LSJkYRCEyh3qT9-Hp-EeurW6ObYLMa2s2T3vXEg7UeTCWtp3B4WSxCzJQnK80mIrQsViY2F5tKG_lIAdUxmY2Nh7TbgrLClNjTVI1E2BK6D-jKMVp6xr0uMcJrCg2SBE5e8r0xYqCRVu52ig0D4PxvJ-cb9Yx5w2ajOhoLOKtyp_eO4N9L8WljQ885iBx8TFPl0pY_2E3fjG0PPGBDSQvggV6O83wfYPKQ7kfBgp0d4z57RfbUye2RtV8sulN47grFW4HTn9Pf0BH-kNN4p2yhoIqSUNfbGWxoaBzeIJ11DABdZVffunR9jSppi4X3JApuHHhS4BGn0jUmyqS3ZF96kg1WQGwJuLrX0osXDzUkIMJxnrV3savYGS24huZXa7tq-dWaidRjrx-WZuBQnizuCUaOXfdb8ttOKUCdvHsc74_BHbQ56lPbbx9I0oV-E-X3dFo0MZHR7gF3WCUIThpRA11aZu3IYslcYRExYifqBAw9jBgXbiys6tCo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"images/20220708_144639.jpg\")\n",
    "print(img.shape)\n",
    "\n",
    "# Convert the image from BGR to RGB format\n",
    "img = cv2.cvtColor(\n",
    "    img, cv2.COLOR_BGR2RGB\n",
    ")  # BGR to RGB for converting CV2 image to matplotlib image\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"images/20220708_144639.jpg\")\n",
    "print(img.shape)\n",
    "\n",
    "# Split the image into channels\n",
    "b = img[:, :, 0]\n",
    "g = img[:, :, 1]\n",
    "r = img[:, :, 2]\n",
    "\n",
    "# Display the images using matplotlib\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "axs[0, 0].imshow(img[:, :, ::-1])  # BGR to RGB\n",
    "axs[0, 0].set_title(\"Original Image\")\n",
    "axs[0, 0].axis(\"off\")\n",
    "\n",
    "axs[0, 1].imshow(b, cmap=\"gray\")\n",
    "axs[0, 1].set_title(\"Blue Channel\")\n",
    "axs[0, 1].axis(\"off\")\n",
    "\n",
    "axs[1, 0].imshow(g, cmap=\"gray\")\n",
    "axs[1, 0].set_title(\"Green Channel\")\n",
    "axs[1, 0].axis(\"off\")\n",
    "\n",
    "axs[1, 1].imshow(r, cmap=\"gray\")\n",
    "axs[1, 1].set_title(\"Red Channel\")\n",
    "axs[1, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV | DNN | https://docs.opencv.org/4.x/d6/d0f/group__dnn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cv2_vid = cv2.VideoCapture(\n",
    "    \"images/shore.mp4\"\n",
    ")  # Provide the path of the video or Zero for webcam\n",
    "\n",
    "if cv2_vid.isOpened() == False:\n",
    "    print(\"Cannot open file or video stream\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cv2_vid.read()\n",
    "\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == 27:  # Press ESC to exit or wait for 10 ms\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get files: bvlc_googlenet.caffemodel & bvlc_googlenet.prototxt | https://github.com/BVLC/caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"images/20220708_144639.jpg\")\n",
    "print(img.shape)\n",
    "\n",
    "all_rows = open(\"model/synset_words.txt\").read().strip().split(\"\\n\")\n",
    "\n",
    "classes = [r[r.find(\" \") + 1 :] for r in all_rows]\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    if i == 4:\n",
    "        break\n",
    "    print(i, c)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"images/20220708_144639.jpg\")\n",
    "print(\"img.shape\", img.shape)\n",
    "\n",
    "all_rows = open(\"model/synset_words.txt\").read().strip().split(\"\\n\")\n",
    "\n",
    "classes = [r[r.find(\" \") + 1 :] for r in all_rows]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"model/bvlc_googlenet.prototxt\", \"model/bvlc_googlenet.caffemodel\"\n",
    ")\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224))\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outp = net.forward()\n",
    "print(\"outp- net.forward()\")\n",
    "print(outp[0][:5])\n",
    "print(outp[0][-5:])\n",
    "\n",
    "idx = np.argsort(outp[0])[::-1][:5]\n",
    "\n",
    "for i, id in enumerate(idx):\n",
    "    print(\n",
    "        \"{}. {} ({}): Probability {:.3}%\".format(\n",
    "            i + 1, classes[id], id, outp[0][id] * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"images/shore.mp4\")\n",
    "\n",
    "all_rows = open(\"model/synset_words.txt\").read().strip().split(\"\\n\")\n",
    "\n",
    "classes = [r[r.find(\" \") + 1 :] for r in all_rows]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"model/bvlc_googlenet.prototxt\", \"model/bvlc_googlenet.caffemodel\"\n",
    ")\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"Cannot open file or video stream\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (224, 224))\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    outp = net.forward()\n",
    "\n",
    "    r = 1\n",
    "    for i in np.argsort(outp[0])[::-1][:5]:\n",
    "        txt = ' \"%s\" probability \"%.3f\" ' % (classes[i], outp[0][i] * 100)\n",
    "        cv2.putText(\n",
    "            frame, txt, (0, 25 + 40 * r), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2\n",
    "        )\n",
    "        r += 1\n",
    "\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
